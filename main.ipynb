{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2140 entries, 0 to 2139\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   date                  2140 non-null   object \n",
      " 1   avg_price             2140 non-null   float64\n",
      " 2   active_addresses      2140 non-null   int64  \n",
      " 3   google_trends         2140 non-null   float64\n",
      " 4   top100_coins_percent  2140 non-null   float64\n",
      " 5   avg_polarity          2140 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 100.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./dataset/interpolate_dataset.csv')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [],
   "source": [
    "# get features by slidng window\n",
    "X=[]\n",
    "y=[]\n",
    "timesteps = 30\n",
    "for row in range(timesteps,2140):\n",
    "    df_row=df.iloc[(row-timesteps):row]\n",
    "    # use previous five day's data as features, so there will be 25 features\n",
    "    # previous five day's avg_price\n",
    "    f1=df_row['avg_price'].tolist()\n",
    "    # previous five day's active_addresses\n",
    "    f2=df_row['active_addresses'].tolist()\n",
    "    # previous five day's google_trends\n",
    "    f3=df_row['google_trends'].tolist()\n",
    "    # previous five day's top100_coins_percent\n",
    "    f4=df_row['top100_coins_percent'].tolist()\n",
    "    # previous five day's avg_polarity\n",
    "    f5=df_row['avg_polarity'].tolist()\n",
    "    featues=f1+f2+f3+f4+f5\n",
    "    X.append(featues)\n",
    "    # label: avg_price\n",
    "    y.append(df['avg_price'].iloc[row])\n",
    "# tranfrom X to dataframe\n",
    "cols1=['avg_price_'+str(i) for i in range(1,timesteps+1)]\n",
    "cols2=['active_addresses_'+str(i) for i in range(1,timesteps+1)]\n",
    "cols3=['google_trends_'+str(i) for i in range(1,timesteps+1)]\n",
    "cols4=['top100_coins_percent_'+str(i) for i in range(1,timesteps+1)]\n",
    "cols5=['avg_polarity_'+str(i) for i in range(1,timesteps+1)]\n",
    "X=pd.DataFrame(X,columns=cols1+cols2+cols3+cols4+cols5)\n",
    "# transform y to series\n",
    "y=pd.Series(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [],
   "source": [
    "# train set: 1708 test set: 427\n",
    "X_train=X.iloc[:1708]\n",
    "X_test=X.iloc[1708:]\n",
    "y_train=y.iloc[:1708]\n",
    "y_test=y.iloc[1708:]\n",
    "feature_columns = X.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [],
   "source": [
    "#z-score normalization\n",
    "std=StandardScaler()\n",
    "# fit and transform train set\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train,columns=feature_columns)\n",
    "# transform test set\n",
    "X_test=std.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test,columns=feature_columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(max_depth=8, n_estimators=200, random_state=0)"
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "rf_reg=RandomForestRegressor(n_estimators=200,max_depth=8,random_state=0)\n",
    "rf_reg.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingRegressor(max_depth=7, min_samples_leaf=60,\n                          min_samples_split=300, random_state=0)"
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100,min_samples_split=300,max_depth=7,random_state=0,min_samples_leaf=60)\n",
    "gbr.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingRegressor(estimators=[('gbr',\n                             GradientBoostingRegressor(max_depth=7,\n                                                       min_samples_leaf=60,\n                                                       min_samples_split=300,\n                                                       random_state=0)),\n                            ('rf',\n                             RandomForestRegressor(max_depth=8,\n                                                   n_estimators=200,\n                                                   random_state=0))])"
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voting of gbr and rf\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "vote_reg = VotingRegressor(estimators=[('gbr', GradientBoostingRegressor(n_estimators=100,min_samples_split=300,max_depth=7,random_state=0,min_samples_leaf=60)), ('rf', RandomForestRegressor(n_estimators=200,max_depth=8,random_state=0))])\n",
    "vote_reg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def get_accuracy(y_test,y_pred):\n",
    "    y_test = list(y_test)\n",
    "    y_pred = list(y_pred)\n",
    "    return 1 - sum([abs(y_pred[i] - y_test[i])/y_test[i] for i in range(len(y_pred))])/len(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest:\n",
      "accuracy:90.98%\n",
      "RMSE:2918.997506744741\n",
      "MSE:8520546.444382012\n",
      "R-square:0.9573964567335109\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gradient boosting regression:\n",
      "accuracy:89.01%\n",
      "RMSE:4006.693661999588\n",
      "MSE:16053594.10110767\n",
      "R-square:0.9197305014022724\n",
      "\n",
      "\n",
      "voting model (lr,lr,lr) regression:\n",
      "accuracy:90.08%\n",
      "RMSE:3392.4019814765775\n",
      "MSE:11508391.20392621\n",
      "R-square:0.9424569485320476\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "pred_test1=rf_reg.predict(X_test)\n",
    "# calculate accuracy\n",
    "accuracy = get_accuracy(y_test,pred_test1)\n",
    "print('random forest:')\n",
    "print(f\"accuracy:{round(accuracy,4) * 100}%\")\n",
    "print(f\"RMSE:{mean_squared_error(y_test,pred_test1,squared=False)}\")\n",
    "print(f\"MSE:{mean_squared_error(y_test,pred_test1,squared=True)}\")\n",
    "print(f\"R-square:{r2_score(y_test,pred_test1)}\")\n",
    "\n",
    "print('\\n')\n",
    "pred_test2=gbr.predict(X_test)\n",
    "accuracy = get_accuracy(y_test,pred_test2)\n",
    "print('gradient boosting regression:')\n",
    "print(f\"accuracy:{round(accuracy,4) * 100}%\")\n",
    "print(f\"RMSE:{mean_squared_error(y_test,pred_test2,squared=False)}\")\n",
    "print(f\"MSE:{mean_squared_error(y_test,pred_test2,squared=True)}\")\n",
    "print(f\"R-square:{r2_score(y_test,pred_test2)}\")\n",
    "\n",
    "print('\\n')\n",
    "pred_test3=vote_reg.predict(X_test)\n",
    "accuracy = get_accuracy(y_test,pred_test3)\n",
    "print('voting model (lr,lr,lr) regression:')\n",
    "print(f\"accuracy:{round(accuracy,4) * 100}%\")\n",
    "print(f\"RMSE:{mean_squared_error(y_test,pred_test3,squared=False)}\")\n",
    "print(f\"MSE:{mean_squared_error(y_test,pred_test3,squared=True)}\")\n",
    "print(f\"R-square:{r2_score(y_test,pred_test3)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "print(list(pred_test1[20:35]))\n",
    "print(list(pred_test2[20:35]))\n",
    "print(list(pred_test3[20:35]))\n",
    "tests = list(y_test[20:35])\n",
    "print(tests)\n",
    "plt.plot(tests,label='Real Price')\n",
    "plt.plot(pred_test1[20:35], \"gd\", label=\"GradientBoostingRegressor\")\n",
    "plt.plot(pred_test2[20:35], \"b^\", label=\"RandomForestRegressor\")\n",
    "plt.plot(pred_test3[20:35], \"r*\", ms=10, label=\"VotingRegressor\")\n",
    "plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "plt.ylabel(\"predicted\")\n",
    "plt.xlabel(\"training samples\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Regressor predictions and their average\")\n",
    "plt.savefig(r'D:\\semA\\COMP 5567\\5567project\\picture\\regressor.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
